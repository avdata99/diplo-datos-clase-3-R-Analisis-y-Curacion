---
title: "Práctico 2. Clase 4 de Análisis y Curación"
output: html_notebook
author: Andrés Vázquez
---

## Ejercicio
### Diagnosticando Cancer

* Investigaremos ahora la utilidad del ML para detectar cancer aplicandoel algoritmo kNN a mediciones de biopsias de mujeres, utilizando el  conjunto de datos  "Breast Cancer Winscosin Diagnostic" del UCI ML Repository <http://archive.ics.uci.edu/ml> que incluye 569 ejemplos de biopsias, en cada una se midieron 32 features  (diferentes caracteristicas de las nucleos celulares) y el diagnostico codificado como M (Maligno) o B (Benigno).

```{r}
# Obtener datos
data <- read.csv("http://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data",header=FALSE)
data <- data[-1]  # se saca la primera columna
print(data)
```

+ Mejore el rendimiento utilizando una normalizacion con z-scores provista por la funcion scale() de R.


```{r}

# MI FUNCION Z-SCORE
zscore <- function(x) {
  return ((x-mean(x)) / sd(x))
}

# # PROBANDO MI Z-SCORE
# zscore(c(1,2,3,4,5))
# zscore(c(10,20,30,40,50))
# 
# # PROBANDO MI Z-SCORE con outliers
# zscore(c(1,2,3,4,5, 1000))
# zscore(c(10,20,30,40,50, 10000))

data_n_z <- as.data.frame(lapply(data[2:31], zscore))
# summary(data_n_z$V3)
# summary(data_n_z$V8)

data_train_z <- data_n_z[1:469, ]
data_test_z  <- data_n_z[470:569, ] 

data_train_labels <- data[1:469, 1]
data_test_labels  <- data[470:569, 1]

library(class)
data_test_pred_z <- knn(train=data_train_z, test=data_test_z, cl=data_train_labels, k=21)

library(gmodels)
CrossTable(x=data_test_labels, y=data_test_pred_z, prop.chisq = FALSE)
```

+ Pruebe algunos valores alternativos de k=1, 5,  11, 15, 21 y seleccione el mejor valor de k.

```{r}
data_test_pred_z <- knn(train=data_train_z, test=data_test_z, cl=data_train_labels, k=1)
CrossTable(x=data_test_labels, y=data_test_pred_z, prop.chisq = FALSE)
```

```{r}
data_test_pred_z <- knn(train=data_train_z, test=data_test_z, cl=data_train_labels, k=5)
CrossTable(x=data_test_labels, y=data_test_pred_z, prop.chisq = FALSE)
```

```{r}
data_test_pred_z <- knn(train=data_train_z, test=data_test_z, cl=data_train_labels, k=11)
CrossTable(x=data_test_labels, y=data_test_pred_z, prop.chisq = FALSE)
```

```{r}
data_test_pred_z <- knn(train=data_train_z, test=data_test_z, cl=data_train_labels, k=15)
CrossTable(x=data_test_labels, y=data_test_pred_z, prop.chisq = FALSE)
```

```{r}
data_test_pred_z <- knn(train=data_train_z, test=data_test_z, cl=data_train_labels, k=21)
CrossTable(x=data_test_labels, y=data_test_pred_z, prop.chisq = FALSE)
```

+ mientras termina su merecido cafe verifique si el resultado cambia utilizando paciente elegidos aleatoriamente para el conjunto de validacion.

```{r}
print("#TODO Ver cual es la forma de medir cual es el mejor")
```


## Probar si los resultados cambian tomando diferentes datos de test y entrenamiento

Tomo los primeros 100 con test y los restantes como entrenamiento

```{r}
data_train_z <- data_n_z[101:569, ]
data_test_z  <- data_n_z[1:100, ] 

data_train_labels <- data[101:569, 1]
data_test_labels  <- data[1:100, 1]

data_test_pred_z <- knn(train=data_train_z, test=data_test_z, cl=data_train_labels, k=11)
CrossTable(x=data_test_labels, y=data_test_pred_z, prop.chisq = FALSE)

```

Los resultados son parecidos ¿Cómo evalúo las diferencias
