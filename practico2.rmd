---
title: "Práctico 2. Clase 4 de Análisis y Curación"
output: html_notebook
author:
  - name: Andrés Vázquez
  - name: Sergio Buzzi
editor_options: 
  chunk_output_type: inline
---

## Ejercicio
### Diagnosticando Cancer

* Investigaremos ahora la utilidad del ML para detectar cancer aplicandoel algoritmo kNN a mediciones de biopsias de mujeres, utilizando el  conjunto de datos  "Breast Cancer Winscosin Diagnostic" del UCI ML Repository <http://archive.ics.uci.edu/ml> que incluye 569 ejemplos de biopsias, en cada una se midieron 32 features  (diferentes caracteristicas de las nucleos celulares) y el diagnostico codificado como M (Maligno) o B (Benigno).

```{r}
# Obtener datos
data <- read.csv("http://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data",header=FALSE)
data <- data[-1]  # se saca la primera columna
print(data)
```

+ Mejore el rendimiento utilizando una normalizacion con z-scores provista por la funcion scale() de R.


```{r}

# MI FUNCION Z-SCORE
zscore <- function(x) {
  return ((x-mean(x)) / sd(x))
}

# # PROBANDO MI Z-SCORE
# zscore(c(1,2,3,4,5))
# zscore(c(10,20,30,40,50))
# 
# # PROBANDO MI Z-SCORE con outliers
# zscore(c(1,2,3,4,5, 1000))
# zscore(c(10,20,30,40,50, 10000))

data_n_z <- as.data.frame(lapply(data[2:31], zscore))
# summary(data_n_z$V3)
# summary(data_n_z$V8)

# o bien usando la función scale
#data_n_z_scale <- scale(x, center = TRUE, scale=TRUE)
#mean(data_n_z_scale)
#sd(data_n_z_scale)

data_train_z <- data_n_z[1:469, ]
data_test_z  <- data_n_z[470:569, ] 

data_train_labels <- data[1:469, 1]
data_test_labels  <- data[470:569, 1]

library(class)
data_test_pred_z <- knn(train=data_train_z, test=data_test_z, cl=data_train_labels, k=21)

library(gmodels)
CrossTable(x=data_test_labels, y=data_test_pred_z, prop.chisq = FALSE)


```

+ Pruebe algunos valores alternativos de k=1, 5,  11, 15, 21 y seleccione el mejor valor de k.

```{r}
data_test_pred_z <- knn(train=data_train_z, test=data_test_z, cl=data_train_labels, k=1)
CrossTable(x=data_test_labels, y=data_test_pred_z, prop.chisq = FALSE)
temp <- CrossTable(x=data_test_labels, y=data_test_pred_z, prop.chisq = FALSE)
porcentaje_clasif_correctas_k_1= 100*(temp$t[1,1]+temp$t[2,2])/sum(temp$t)

```

```{r}
data_test_pred_z <- knn(train=data_train_z, test=data_test_z, cl=data_train_labels, k=5)
CrossTable(x=data_test_labels, y=data_test_pred_z, prop.chisq = FALSE)
temp <- CrossTable(x=data_test_labels, y=data_test_pred_z, prop.chisq = FALSE)
porcentaje_clasif_correctas_k_5= 100*(temp$t[1,1]+temp$t[2,2])/sum(temp$t)

```

```{r}
data_test_pred_z <- knn(train=data_train_z, test=data_test_z, cl=data_train_labels, k=11)
CrossTable(x=data_test_labels, y=data_test_pred_z, prop.chisq = FALSE)
temp <- CrossTable(x=data_test_labels, y=data_test_pred_z, prop.chisq = FALSE)
porcentaje_clasif_correctas_k_11= 100*(temp$t[1,1]+temp$t[2,2])/sum(temp$t)

```

```{r}
data_test_pred_z <- knn(train=data_train_z, test=data_test_z, cl=data_train_labels, k=15)
CrossTable(x=data_test_labels, y=data_test_pred_z, prop.chisq = FALSE)
temp <- CrossTable(x=data_test_labels, y=data_test_pred_z, prop.chisq = FALSE)
porcentaje_clasif_correctas_k_15= 100*(temp$t[1,1]+temp$t[2,2])/sum(temp$t)

```

```{r}
data_test_pred_z <- knn(train=data_train_z, test=data_test_z, cl=data_train_labels, k=21)
CrossTable(x=data_test_labels, y=data_test_pred_z, prop.chisq = FALSE)
temp <- CrossTable(x=data_test_labels, y=data_test_pred_z, prop.chisq = FALSE)
porcentaje_clasif_correctas_k_21= 100*(temp$t[1,1]+temp$t[2,2])/sum(temp$t)
```

Se pueden costruir varios ratios, el que primero se sabe ver es el porcentaje de clasificaciones correctas: (BB+MM)/TOTAL.

```{r}
#print("#TODO Ver cual es la forma de medir cual es el mejor")
library(knitr)
kable(data.frame(c(1,5,11,15,21),
c(porcentaje_clasif_correctas_k_1,porcentaje_clasif_correctas_k_5,porcentaje_clasif_correctas_k_11,porcentaje_clasif_correctas_k_15,porcentaje_clasif_correctas_k_21)), col.names = c("k", "Porc. Clasif. Correcta"))

```

De acuerdo a ese criterio funcionan mejor lo valores mas grandes de k (11, 15 y 21).


+ mientras termina su merecido cafe verifique si el resultado cambia utilizando paciente elegidos aleatoriamente para el conjunto de validacion.


## Probar si los resultados cambian tomando diferentes datos de test y entrenamiento

Tomo los primeros 100 con test y los restantes como entrenamiento

```{r}
data_train_z <- data_n_z[101:569, ]
data_test_z  <- data_n_z[1:100, ] 

data_train_labels <- data[101:569, 1]
data_test_labels  <- data[1:100, 1]

data_test_pred_z <- knn(train=data_train_z, test=data_test_z, cl=data_train_labels, k=11)
CrossTable(x=data_test_labels, y=data_test_pred_z, prop.chisq = FALSE)
temp <- CrossTable(x=data_test_labels, y=data_test_pred_z, prop.chisq = FALSE)
porcentaje_clasif_correctas_k11_otra_muestra= 100*(temp$t[1,1]+temp$t[2,2])/sum(temp$t)
porcentaje_clasif_correctas_k11_otra_muestra
```

Los resultados son parecidos, en este caso particular, usando k=11, se califica correctamente el 91% de los casos, mientras que con la muestra anterior (con el mismo k=11), se clasificaba correctamente el 98% de los casos, o sea que el desempeño empeora. 
